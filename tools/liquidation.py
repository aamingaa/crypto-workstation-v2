import os
from tardis_dev import datasets, get_exchange_details
import pandas as pd
from tardis_client import TardisClient, Channel
import pandas as pd
import numpy as np
import asyncio
from typing import Optional, List
from tardis_secrets import TARDIS_API_KEY as API_KEY
DOWNLOAD_DIR = "/Users/aming/data/ETHUSDT"

# å¸¸è§å€™é€‰ï¼ˆä¸åŒç‰ˆæœ¬/è´¦æˆ·æƒé™å¯èƒ½ç•¥æœ‰å·®å¼‚ï¼›è·‘ä¸€ä¸‹å°±çŸ¥é“ä½ è´¦æˆ·èƒ½ç”¨å“ªäº›ï¼‰
CANDIDATE_EXCHANGES = [
    # "binance",          # çŽ°è´§
    "binance-futures",  # åˆçº¦ï¼ˆå¾ˆå¤šè´¦æˆ·æ˜¯è¿™ä¸ª idï¼‰
    # "binance-usdm",     # æœ‰çš„è´¦æˆ·ä¼šæ‹†æˆ usdm/coinm
    # "binance-coinm",
]
client = TardisClient(api_key=API_KEY)

async def replay_data(exchange: str="binance-futures", from_date: str="2023-01-01", to_date: str="2023-01-02", channel_name: str="topLongShortAccountRatio", symbols: Optional[List[str]] = ["ethusdt"]):
    # è®¾å®šè¦ä¸‹è½½çš„æ—¶é—´æ®µ (Tardis ä¿å­˜äº†æ•°å¹´çš„åŽ†å²æ•°æ®)
    messages = client.replay(
        exchange=exchange,
        from_date=from_date,
        to_date=to_date,
        filters=[
            # èŽ·å–èµ„é‡‘è´¹çŽ‡ (é€šå¸¸åœ¨ ticker ä¸­)
            # Channel(name="derivative_ticker", symbols=["BTCUSDT"]),
            
            # èŽ·å–å¤šç©ºæ•°æ® (è¿™æ˜¯ Tardis çš„ç‰¹æ®Šåˆæˆé¢‘é“)
            Channel(name=channel_name, symbols=symbols),
            # Channel(name="topLongShortPositionRatio", symbols=["BTCUSDT"]),
        ]
    )

    # ä¿å­˜å•ä¸ªæœˆä»½æ•°æ®çš„å‡½æ•°
    def save_month_data(month_str: str, data_list: list, out_dir: str):
        if not data_list:
            return
        df_month = pd.DataFrame(data_list)
        df_month.rename(columns={'time': 'open_time'}, inplace=True)
        df_month['open_time'] = pd.to_datetime(df_month['open_time'], unit='ms')
        df_month.set_index('open_time', inplace=True)
        df_month.sort_index(inplace=True)
        
        out_path = os.path.join(out_dir, f"{channel_name}_{month_str}.csv")
        df_month.to_csv(out_path)
        print(f"âœ… å·²ä¿å­˜: {month_str} -> {len(df_month)} æ¡è®°å½•")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    out_dir = os.path.join(DOWNLOAD_DIR, channel_name)
    os.makedirs(out_dir, exist_ok=True)
    print(f"å¼€å§‹èŽ·å–æ•°æ®ï¼Œä¿å­˜è·¯å¾„: {out_dir}\n")
    
    # å­˜å‚¨å½“å‰æœˆä»½çš„æ•°æ®
    current_month_key = None
    current_month_data = []
    count = 0
    saved_months = 0
    
    # å¾ªçŽ¯å¤„ç†æ¯ä¸€æ¡åŽ†å²æ¶ˆæ¯
    async for local_timestamp, message in messages:
        # å¤„ç†æ•°æ®
        msg = message['data']
        count += 1
        
        # èŽ·å–æ—¶é—´æˆ³å¹¶ç¡®å®šæ‰€å±žæœˆä»½
        timestamp = pd.to_datetime(msg['time'], unit='ms')
        month_key = timestamp.strftime("%Y-%m")
        
        # æ£€æµ‹åˆ°æœˆä»½åˆ‡æ¢ï¼šä¿å­˜ä¸Šä¸ªæœˆçš„æ•°æ®
        if current_month_key is not None and month_key != current_month_key:
            save_month_data(current_month_key, current_month_data, out_dir)
            saved_months += 1
            current_month_data = []  # æ¸…ç©ºï¼Œé‡Šæ”¾å†…å­˜
        
        # æ›´æ–°å½“å‰æœˆä»½
        current_month_key = month_key
        current_month_data.append(msg)
        
        # è¿›åº¦æç¤º
        if count % 3000 == 0:
            print(f"å·²èŽ·å– {count} æ¡æ•°æ® | å½“å‰æ—¶é—´: {timestamp} | å½“å‰æœˆä»½: {month_key} | å·²ä¿å­˜æœˆä»½: {saved_months}")
    
    # ä¿å­˜æœ€åŽä¸€ä¸ªæœˆçš„æ•°æ®
    if current_month_data:
        save_month_data(current_month_key, current_month_data, out_dir)
        saved_months += 1
    
    print(f"\nðŸŽ‰ æ•°æ®èŽ·å–å®Œæˆï¼æ€»å…± {count} æ¡æ•°æ®ï¼Œä¿å­˜äº† {saved_months} ä¸ªæœˆä»½")


def show_exchange(exchange_id: str):
    try:
        details = get_exchange_details(exchange_id)
    except Exception as e:
        print(f"[{exchange_id}] get_exchange_details failed: {e}")
        return None

    # dataTypes å¾€å¾€åœ¨ details["datasets"]["symbols"][i]["dataTypes"]
    ds = details.get("datasets", {})
    symbols = ds.get("symbols", []) or []
    print(f"\n=== {exchange_id} ===")
    print("symbol count:", len(symbols))
    if symbols:
        # å–å‰å‡ ä¸ª symbol æ±‡æ€» dataTypes
        all_types = set()
        for s in symbols[:50]:
            for t in s.get("dataTypes", []) or []:
                all_types.add(t)
        print("sample dataTypes:", sorted(all_types))
        print("sample symbols:", [symbols[i].get("id") for i in range(min(5, len(symbols)))])
    return details

def find_types(details, keywords=("book_snapshot_25", "book_snapshot_5", "book_ticker", "derivative_ticker", "incremental_book_L2", "liquidations", "quotes", "trades")):
    ds = details.get("datasets", {})
    symbols = ds.get("symbols", []) or []
    all_types = set()
    for s in symbols:
        for t in s.get("dataTypes", []) or []:
            all_types.add(t)
    hits = [t for t in sorted(all_types) if any(k.lower() in t.lower() for k in keywords)]
    return hits

def download(exchange_id: str, symbol: str, data_types, from_date: str, to_date: str):
    datasets.download(
        exchange=exchange_id,
        data_types=data_types,
        from_date=from_date,
        format="csv",
        to_date=to_date,     # éžåŒ…å«
        symbols=[symbol],
        api_key=API_KEY,
        download_dir=DOWNLOAD_DIR,
    )

def list_days(from_date: str, to_date: str, inclusive_end: bool = False) -> Optional[List[str]]:
    """
    èŽ·å– from_date åˆ° to_date çš„æ¯ä¸€å¤©ï¼ˆYYYY-MM-DD å­—ç¬¦ä¸²ï¼‰ã€‚
    - é»˜è®¤å·¦é—­å³å¼€ï¼š[from_date, to_date)ï¼Œä¸Ž tardis_dev çš„ to_date éžåŒ…å«è¯­ä¹‰ä¸€è‡´
    - inclusive_end=True æ—¶ä¸ºé—­åŒºé—´ï¼š[from_date, to_date]
    """
    # pandas>=1.4 æ”¯æŒ inclusive=...
    inclusive = "both" if inclusive_end else "left"
    return pd.date_range(start=from_date, end=to_date, freq="D", inclusive=inclusive).strftime("%Y-%m-%d").tolist()

def read_liquidations_data(symbol: str="ETHUSDT", from_date: str="2025-02-01", to_date: str="2025-02-02"):
   
    _list_days = list_days(from_date, to_date)
    df_list = []
    for day in _list_days:
        df = pd.read_csv(f"{DOWNLOAD_DIR}/liquidations/binance-futures_liquidations_{day}_{symbol}.csv.gz")
        df.rename(columns={'timestamp': 'open_time'}, inplace=True)
        df['open_time'] = pd.to_datetime(df['open_time'], unit='us')
        df.set_index('open_time', inplace=True)
        df.drop(columns=['symbol', 'local_timestamp', 'id'], inplace=True)
        df_list.append(df)
    result_df = pd.concat(df_list)
    result_df.sort_index(inplace=True)
    return result_df

def deal_liquidations_data(df: pd.DataFrame, freq: str="15min"):
    df['usd_value'] = df['price'] * df['amount']

    # åˆ©ç”¨ numpy çš„ where å¿«é€Ÿæ‹†åˆ†å¤šç©ºçˆ†ä»“
    # side == 'buy' æ„å‘³ç€äº¤æ˜“æ‰€ä¹°å…¥å¹³ä»“ -> ç”¨æˆ·æ˜¯ç©ºå¤´ -> Short Liquidation
    df['short_liq_vol'] = np.where(df['side'] == 'buy', df['usd_value'], 0)
    df['short_liq_cnt'] = np.where(df['side'] == 'buy', 1, 0)

    # side == 'sell' æ„å‘³ç€äº¤æ˜“æ‰€å–å‡ºå¹³ä»“ -> ç”¨æˆ·æ˜¯å¤šå¤´ -> Long Liquidation
    df['long_liq_vol'] = np.where(df['side'] == 'sell', df['usd_value'], 0)
    df['long_liq_cnt'] = np.where(df['side'] == 'sell', 1, 0)

    # 3. èšåˆï¼šResample åˆ° 15min çº§åˆ«
    # rule='15min' è¡¨ç¤º 15åˆ†é’Ÿç²’åº¦
    # closed='left', label='left' æ˜¯é‡åŒ–å¸¸ç”¨ä¹ æƒ¯ï¼ˆ00:00:00 çš„æ•°æ®åŒ…å« 00:00~00:14:59ï¼‰
    df_freq = df.resample(freq, label='left', closed='left').agg({
        'short_liq_vol': 'sum',  # ç©ºå¤´çˆ†ä»“æ€»é‡‘é¢
        'short_liq_cnt': 'sum',  # ç©ºå¤´çˆ†ä»“æ¬¡æ•°
        'long_liq_vol':  'sum',  # å¤šå¤´çˆ†ä»“æ€»é‡‘é¢
        'long_liq_cnt':  'sum',  # å¤šå¤´çˆ†ä»“æ¬¡æ•°
        'price': ['first', 'max', 'min', 'last'], # (å¯é€‰) çœ‹çœ‹çˆ†ä»“æ—¶çš„ä»·æ ¼åˆ†å¸ƒ
        'exchange': 'count'      # æ€»çˆ†ä»“å•æ•°
    })

    # 4. æ‰å¹³åŒ–åˆ—å (å¯é€‰ï¼Œä¸ºäº†æ–¹ä¾¿è®¿é—®)
    df_freq.columns = ['_'.join(col).strip() for col in df_freq.columns.values]
    # ä¿®æ­£åŽåˆ—åç¤ºä¾‹: short_liq_vol_sum, long_liq_vol_sum

    # 5. ç¼ºå¤±å€¼å¡«å……
    # å¦‚æžœæŸ 15min å†…æ²¡æœ‰çˆ†ä»“ï¼Œresample ä¼šäº§ç”Ÿ NaNï¼Œéœ€è¦å¡« 0
    df_freq.fillna(0, inplace=True)

    # 6. è¡ç”Ÿé«˜é˜¶å› å­ (Feature Engineering)
    # å‡€çˆ†ä»“æ–¹å‘ï¼š>0 ä»£è¡¨ç©ºå¤´çˆ†å¾—æ›´å¤šï¼ˆåŠ©æ¶¨ï¼‰ï¼Œ<0 ä»£è¡¨å¤šå¤´çˆ†å¾—æ›´å¤šï¼ˆåŠ©è·Œï¼‰
    df_freq['net_liq_vol'] = df_freq['short_liq_vol_sum'] - df_freq['long_liq_vol_sum']

    # çˆ†ä»“å¼ºåº¦æ¯”ï¼šç©ºå¤´çˆ†ä»“å æ¯”
    df_freq['short_liq_ratio'] = df_freq['short_liq_vol_sum'] / (df_freq['short_liq_vol_sum'] + df_freq['long_liq_vol_sum'] + 1e-6)
    # print(df_15m.head())
    return df_freq

def read_liquidations_data(symbol: str="ETHUSDT", from_date: str="2025-02-01", to_date: str="2025-02-02"):
   
    _list_days = list_days(from_date, to_date)
    df_list = []
    for day in _list_days:
        df = pd.read_csv(f"{DOWNLOAD_DIR}/liquidations/binance-futures_liquidations_{day}_{symbol}.csv.gz")
        df.rename(columns={'timestamp': 'open_time'}, inplace=True)
        df['open_time'] = pd.to_datetime(df['open_time'], unit='us')
        df.set_index('open_time', inplace=True)
        df.drop(columns=['symbol', 'local_timestamp', 'id'], inplace=True)
        df_list.append(df)
    result_df = pd.concat(df_list)
    result_df.sort_index(inplace=True)
    return result_df

def read_derivative_ticker_data(symbol: str="ETHUSDT", from_date: str="2025-02-01", to_date: str="2025-02-02"):
   
    _list_days = list_days(from_date, to_date)
    df_list = []
    for day in _list_days:
        df = pd.read_csv(f"{DOWNLOAD_DIR}/derivative_ticker/binance-futures_derivative_ticker_{day}_{symbol}.csv.gz")
        df.rename(columns={'timestamp': 'open_time'}, inplace=True)
        df['open_time'] = pd.to_datetime(df['open_time'], unit='us')
        df['funding_timestamp'] = pd.to_datetime(df['funding_timestamp'], unit='us')
        df.set_index('open_time', inplace=True)
        df.drop(columns=['exchange', 'local_timestamp', 'symbol'], inplace=True)
        df_list.append(df)
    result_df = pd.concat(df_list)
    result_df.sort_index(inplace=True)
    return result_df

def deal_derivative_ticker_data(df: pd.DataFrame, freq: str="15min"):
    # 2. èšåˆåˆ° 15min
    # æ³¨æ„ï¼šå¯¹äºŽçŠ¶æ€æ•°æ®ï¼ˆOIã€è´¹çŽ‡ï¼‰ï¼Œæˆ‘ä»¬é€šå¸¸å…³å¿ƒè¯¥æ—¶é—´çª—å£ç»“æŸæ—¶çš„çŠ¶æ€
    df_freq = df.resample(freq, label='left', closed='left').agg({
        'funding_rate': 'mean',        # è´¹çŽ‡å–å¹³å‡ï¼Œåæ˜ è¯¥æ—¶æ®µæ•´ä½“æƒ…ç»ª
        'predicted_funding_rate': 'last',
        'open_interest': 'last',       # æŒä»“é‡å–æœŸæœ«å€¼
        'index_price': 'last',
        'mark_price': 'last'
    })

    # 3. ç¼ºå¤±å€¼å¤„ç† (Forward Fill)
    # èµ„é‡‘è´¹çŽ‡å’ŒOIä¸ä¼šå‡­ç©ºæ¶ˆå¤±ï¼Œå¦‚æžœæŸ15åˆ†é’Ÿæ²¡æ•°æ®ï¼Œæ²¿ç”¨ä¸Šä¸€æ—¶åˆ»çš„å€¼
    df_freq.fillna(method='ffill', inplace=True)

    # 4. æ ¸å¿ƒç‰¹å¾æž„é€  (Feature Engineering for gplearn)
    # è¿™äº›æ˜¯çœŸæ­£å–‚ç»™ gplearn çš„å› å­

    # A. OI å˜åŒ–çŽ‡ (OI Momentum)
    # é€»è¾‘ï¼šè¿‡åŽ» 15åˆ†é’Ÿæœ‰å¤šå°‘æ–°ä»“ä½è¿›åœºï¼Ÿ
    df_freq['oi_pct_change'] = df_freq['open_interest'].pct_change()

    # B. æœŸé™ç»“æž„/åŸºå·® (Basis)
    # é€»è¾‘ï¼šåˆçº¦æ¯”çŽ°è´§è´µå¤šå°‘ï¼Ÿ(åæ˜ æƒ…ç»ªæº¢ä»·)
    # å½’ä¸€åŒ–å¤„ç†ï¼š(æ ‡è®°ä»·æ ¼ - æŒ‡æ•°ä»·æ ¼) / æŒ‡æ•°ä»·æ ¼
    df_freq['basis_ratio'] = (df_freq['mark_price'] - df_freq['index_price']) / df_freq['index_price']

    # C. è´¹çŽ‡åŠ é€Ÿåº¦ (Funding Acceleration)
    # é€»è¾‘ï¼šè´¹çŽ‡æ˜¯å¦åœ¨å¿«é€Ÿä¸Šå‡ï¼Ÿ
    df_freq['funding_rate_delta'] = df_freq['funding_rate'].diff()
    return df_freq

if __name__ == "__main__":
    # for ex in CANDIDATE_EXCHANGES:
    #     details = show_exchange(ex)
    #     if not details:
    #         continue
    #     print("keyword-matched dataTypes:", find_types(details))

    # ---- ä½ ç¡®è®¤å¥½æŸä¸ª exchange çš„ dataTypes åç§°åŽï¼ŒæŠŠä¸‹é¢æ›¿æ¢æˆçœŸå®žåå­—å³å¯ ----
    # ä¾‹å¦‚ä½ æ‰¾åˆ°çš„å¯èƒ½æ˜¯ ["open_interest", "liquidations", ...derivative_ticker]ï¼ˆä»¥å®žé™…è¾“å‡ºä¸ºå‡†ï¼‰
    
    # download("binance-futures", "ETHUSDT", ["derivative_ticker"], "2022-01-01", "2025-11-01")
   
    # df = read_liquidations_data(symbol="ETHUSDT", from_date="2025-02-01", to_date="2025-02-03")
    # df_freq = deal_liquidations_data(df, freq="15min")
    
    
    # df = read_derivative_ticker_data(symbol="ETHUSDT", from_date="2025-02-01", to_date="2025-02-03")
    # print(df.columns)
    # print(df.head())
    # df_freq = deal_derivative_ticker_data(df, freq="15min")
    # print(df_freq.head())


    # print(df_freq.head())


    # https://docs.tardis.dev/historical-data-details/binance-futures topLongShortPositionRatio topLongShortAccountRatio takerlongshortRatio 
    
    asyncio.run(replay_data(exchange="binance-futures", from_date="2022-01-01", to_date="2024-01-01", channel_name="liquidations", symbols=["ethusdt"]))